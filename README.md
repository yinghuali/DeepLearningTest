# Testing Techniques for Deep Learning Systems

<iframe src="distribution/core_rank.pdf" width="400" height="300"></iframe>
<iframe src="distribution/ccf.pdf" width="400" height="300"></iframe>

## Efficiency-Oriented Testing Techniques

| Year | Title | Venue |
|:---------:|-------|:---------:|
|2025|Prioritizing speech test cases|TOSEM|
|2025|Markov model based coverage testing of deep learning software systems|IST|
|2024|Distance-aware test input selection for deep neural networks|ISSTA|
|2024|Criticalfuzz: A critical neuron coverage-guided fuzz testing framework for deep neural networks|IST|
|2024|Coverage-enhanced fault diagnosis for deep learning programs: A learning-based approach with hybrid metrics|IST|
|2024|Test input prioritization for 3d point clouds|TOSEM|
|2024|Aetta: Label-free accuracy estimation for test-time adaptation|CVPR|
|2024|Deepsample: Dnn sampling-based testing for operational accuracy assessment|ICSE|
|2024|Fast: Boosting uncertainty-based test prioritization methods for neural networks via feature selection|ASE|
|2023|Gnnevaluator: Evaluating gnn performance on unseen graphs without labels|NeurIPS|
|2023|Certpri: certifiable prioritization for deep neural networks via movement cost in feature space|ASE|
|2023|Evaluating surprise adequacy for deep learning system testing|TOSEM|
|2023|Aries: Efficient testing of deep neural networks via labeling-free accuracy estimation|ICSE|
|2023|Graphprior: Mutation-based test input prioritization for graph neural networks|TOSEM|
|2023|Actgraph: prioritization of test cases based on deep neural network activation graph|ASE|
|2022|Adaptive test selection for deep neural networks|ICSE|
|2022|Adaptive test selection for deep neural networks|ICSE|
|2022|Hybridrepair: towards annotation-efficient repair for deep learning models|ISSTA|
|2022|In Defense of Core-set: A Density-aware Core-set Selection for Active Learning|KDD|
|2022|An empirical study on data distribution-aware test selection for deep learning enhancement|TOSEM|
|2022|To actively initialize active learning|PR|
|2022|A white-box testing for deep neural networks based on neuron coverage|TNNLS|
|2022|Npc: Neuron path coverage via characterizing decision logic of deep neural networks|TOSEM|
|2022|Active learning for domain adaptation: An energy-based approach|AAAI|
|2022|Simple techniques work surprisingly well for neural network test prioritization and active learning (replicability study)|ISSTA|
|2022|Boosting active learning via improving test performance|AAAI|
|2021|Efficient active learning for gaussian process classification by error reduction|NeurIPS|
|2021|A review and refinement of surprise adequacy|DeepTest|
|2021|Prioritizing test inputs for deep neural networks via mutation analysis|ICSE|
|2021|Selecting test inputs for DNNs using differential testing with subspecialized model instances|FSE|
|2021|Semi-supervised active learning with temporal output discrepancy|ICCV|
|2021|Batch active learning at scale|NeurIPS|
|2020|Multiple-boundary clustering and prioritization to promote neural network retraining|ASE|
|2020|Cost-effective testing of a deep learning model through input reduction|ISSRE|
|2020|Reducing dnn labelling cost using surprise adequacy: An industrial case study for autonomous driving|FSE|
|2020|Importance-driven deep learning system testing|ICSE|
|2020|Practical accuracy estimation for efficient deep neural network testing|TOSEM|
|2019|Learning Loss for Active Learning|CVPR|
|2019|Deephunter: a coverage-guided fuzz testing framework for deep neural networks|ISSTA|
|2019|Structural test coverage criteria for deep neural networks|TECS|
|2019|Tensorfuzz: Debugging neural networks with coverage-guided fuzzing|ICML|
|2019|Boostingoperational dnn testing efficiency through conditioning|FSE|
|2019|Guiding deep learning system testing using surprise adequacy|ICSE|
|2018|Deeptest: Automated testing of deep-neural-network-driven autonomous cars|ICSE|
|2018|Deepgauge: Multi-granularity testing criteria for deep learning systems|ASE|
|2018|Dlfuzz: Differential fuzzing testing of deep learning systems|FSE|
|2017|Deepxplore: Automated whitebox testing of deep learning systems|SOSP|
|2017|Deep bayesian active learning with image data|ICML|

## Robustness
| Year | Title | Venue |
|:---------:|-------|:---------:|
|2025|Iterative generation of adversarial example for deep code models|ICSE|
|2025|Tapt: Test- time adversarial prompt tuning for robust inference in vision-language models|CVPR|
|2025|Aed-pada: Improving generalizability of adversarial example detec-tion via principal adversarial domain adaptation|TOMM|
|2025|Two is Better than One: Efficient Ensemble Defense for Robust and Compact Models|CVPR|
|2025|MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework|CVPR|
|2024|Attack as detection: Using adversarial attack methods to detect abnormal examples|TOSEM|
|2024|On the duality between sharpness-aware minimization and adversarial training|ICML|
|2024|Improving robustness to corruptions with multiplicative weight perturbations|NeurIPS|
|2024|TabularBench: benchmarking adversarial robustness for tabular deep learning in real-world use-cases|NeurIPS|
|2024|Great score: Global robustness evaluation of adversarial perturbation using generative models|NeurIPS|
|2024|Interpretability-guided test-time adversarial defense|ECCV|
|2024|Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks|ICPC|
|2024|Superdeepfool: a new fast and accurate minimal adversarial attack|NeurIPS|
|2024|BrainWash: A Poisoning Attack to Forget in Continual Learning|CVPR|
|2023|Deeprover: A query-efficient blackbox attack for deep neural networks|FSE|
|2023|A comprehensive evaluation framework for deep model robustness|PR|
|2023|Fedslice: Protecting federated learning models from malicious participants with model slicing|ICSE|
|2023|Model poisoning attack on neural network without reference data|TC|
|2023|Adversarial parameter attack on deep neural networks|ICML|
|2023|A Tale of Two Approximations: Tightening Over-Approximation for DNN Robustness Verification via Under-Approximation|ISSTA|
|2023|Robust test selection for deep neural networks|TSE|
|2023|Understanding and improving ensemble adversarial defense|NeurIPS|
|2022|Toward improving the robustness of deep learning models via model transformation|ASE|
|2022|Adversarial robustness of deep code comment generation|TOSEM|
|2022|Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation|IJCAI|
|2022|You see what i want you to see: poisoning vulnerabilities in neural code search|FSE|
|2022|Îµ-weakened robustness of deep neural networks|ISSTA|
|2022|On the limitations of stochastic pre-processing defenses|NeurIPS|
|2022|Evaluating the adversarial robustness of adaptive test-time defenses|ICML|
|2021|Detecting adversarial samples with graph-guided testing|ASE|
|2021|Understanding local robustness of deep neural networks under natural variations|FASE|
|2021|Robot: Robustness-oriented testing for deep learning systems|ICSE|
|2021|On interaction between aug- mentations and corruptions in natural corruption robustness|NeurIPS|
|2021|Deeppayload: Black-box backdoor attack on deep learning models through neural payload injection|ICSE|
|2021|Robustness of on-device models: Adversarial attack to deep learning models on android apps|ICSE|
|2021|The many faces of robustness: A critical analysis of out-of-distribution generalization|ICCV|
|2020|Towards characterizing adversarial defects of deep learning software from the lens of uncertainty|ICSE|
|2020|Testing dnn image classifiers for confusion & bias errors|ICSE|
|2020|Weight poisoning attacks on pretrained models|ACL|
|2020|Augmix: A simple data processing method to improve robustness and uncertainty|ICLR|
|2020|Fuzz testing based data augmentation to improve robustness of deep neural networks|ICSE|
|2020|Local model poisoning attacks to {Byzantine-Robust} federated learning|USENIX Security|
|2020|Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks|ICML|
|2020|Robust-bench: a standardized adversarial robustness benchmark|arXiv|
|2020|Square attack: a query-efficient black-box adversarial attack via random search|ECCV|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|
|-------|------|-------|

